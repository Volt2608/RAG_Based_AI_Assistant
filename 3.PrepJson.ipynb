{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T10:38:07.682267Z",
     "start_time": "2026-01-02T10:33:18.821952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# since we need to send a list of chunks to an embedding model that runs on a local host, we will send post requests.\n",
    "# port 11434 - Ollama server for embeddings\n",
    "\n",
    "# This script converts lecture chunks into embeddings so they can be semantically searched\n",
    "# and retrieved as part of a RAG system.\n",
    "\n",
    "\n",
    "import os                   # Will use it to list files inside a folder.\n",
    "import requests             # Python library for HTTP, to send a POST request\n",
    "import json                 # To read JSON files\n",
    "import pandas as pd         # to make dataframe\n",
    "import joblib               # to store the saved model for reuse, without running it everytime.\n",
    "\n",
    "\n",
    "# This function: Takes text list, sends it to an embedding model, gets semantic vectors back\n",
    "def create_embedding(text_list):\n",
    "    r = requests.post(\n",
    "    \"http://localhost:11434/api/embed\",\n",
    "    json={                                         # Data being sent to the API in JSON format.\n",
    "        \"model\": \"bge-m3\",                         # bge-m3 converts text into semantic vectors.\n",
    "        \"input\": text_list})\n",
    "\n",
    "    embedding = r.json()[\"embeddings\"]            # Parses JSON body into a Python dict or list\n",
    "    return embedding\n",
    "\n",
    "\n",
    "\n",
    "# Read all JSON files created in the previous step\n",
    "jsons = sorted(os.listdir(\"audio_jsons\"), key=lambda x: int(x.split(\"_\")[1].split(\".\")[0]))          # sorted number wise\n",
    "my_dicts = []                                                                                        # empty list to store all chunks\n",
    "chunk_id = 0                                                                                         # chunk id initialized to 0\n",
    "\n",
    "# Loading every iteration of JSON file using a for loop\n",
    "# The embedding function expects a list of texts, so I batch all chunk text into a list before sending it to the model.\n",
    "\n",
    "for eachFile in jsons:\n",
    "    with open(f\"audio_jsons/{eachFile}\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    print(f\"Processing embedding for : {eachFile}\")\n",
    "\n",
    "    # 1. Collect all chunk text\n",
    "    texts = []\n",
    "    for chunk in data[\"chunks\"]:\n",
    "        texts.append(chunk[\"text\"])\n",
    "\n",
    "    # 2. Call embedding ONCE per file\n",
    "    embeddings = create_embedding(texts)\n",
    "\n",
    "    # 3. Store embeddings with chunks\n",
    "    for i, chunk in enumerate(data[\"chunks\"]):\n",
    "        my_dicts.append({\n",
    "            \"chunk_id\": chunk_id,\n",
    "            \"number\": chunk[\"number\"],\n",
    "            \"text\": chunk[\"text\"],\n",
    "            \"title\": chunk[\"title\"],\n",
    "            \"start\": chunk[\"start\"],\n",
    "            \"end\": chunk[\"end\"],\n",
    "            \"embedding\": embeddings[i]\n",
    "        })\n",
    "        chunk_id += 1\n",
    "\n",
    "\n",
    "    print(\"Completed embedding processing for all chunks\")\n",
    "\n",
    "\n",
    "df = pd.DataFrame.from_records(my_dicts)\n",
    "joblib.dump(df , 'embeddings.joblib')\n",
    "\n",
    "# Line of code explanation:\n",
    "# create a function, that sends text chunks to a local embedding model and returns their vector representations.\n",
    "\n",
    "# WHY THIS FUNCTION -\n",
    "# This function is critical in the RAG pipeline because embeddings allow semantic similarity search,\n",
    "# which enables accurate retrieval of relevant lecture content before generating answers.\n",
    "\n",
    "# 2. I explicitly sort the files numerically to avoid filesystem ordering issues.\n",
    "\n",
    "# 3. The embedding function expects a list of texts, so I batch all chunk text into a list before sending it to the model.\n",
    "\n",
    "# 4. The output is structured so it can be directly inserted into a vector database or queried during retrieval."
   ],
   "id": "f95b0ac7a580f6a0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing embedding for : Lecture_1.mp3.json\n",
      "Completed embedding processing for all chunks\n",
      "Processing embedding for : Lecture_2.mp3.json\n",
      "Completed embedding processing for all chunks\n",
      "Processing embedding for : Lecture_3.mp3.json\n",
      "Completed embedding processing for all chunks\n",
      "Processing embedding for : Lecture_4.mp3.json\n",
      "Completed embedding processing for all chunks\n",
      "Processing embedding for : Lecture_5.mp3.json\n",
      "Completed embedding processing for all chunks\n",
      "Processing embedding for : Lecture_6.mp3.json\n",
      "Completed embedding processing for all chunks\n",
      "Processing embedding for : Lecture_7.mp3.json\n",
      "Completed embedding processing for all chunks\n",
      "Processing embedding for : Lecture_8.mp3.json\n",
      "Completed embedding processing for all chunks\n",
      "Processing embedding for : Lecture_9.mp3.json\n",
      "Completed embedding processing for all chunks\n",
      "Processing embedding for : Lecture_10.mp3.json\n",
      "Completed embedding processing for all chunks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['embeddings.joblib']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
