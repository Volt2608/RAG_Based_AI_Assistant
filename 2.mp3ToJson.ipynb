{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T10:49:31.042658Z",
     "start_time": "2026-01-02T10:48:54.705855Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import whisper                 # imported modules\n",
    "import os\n",
    "import json\n",
    "\n",
    "model = whisper.load_model(\"medium\")                                                        # using model medium for transcription\n",
    "\n",
    "audios = os.listdir(\"audios\")                                                               # listed all audio files in audios folder\n",
    "\n",
    "for audio in audios:                                                                        # iterating through each audio file\n",
    "  number = audio.split(\"_\")[1][:-4]                                                         # extracting number and title from file name\n",
    "  title = audio.split(\"_\")[0]                                                               # extracting title from file name\n",
    "\n",
    "  result = model.transcribe(audio = f\"audios/{audio}\", language=\"en\", task=\"transcribe\")    # transcribing audio file\n",
    "\n",
    "  chunks = []                                                                               # creating an empty list to store chunks\n",
    "  for segment in result[\"segments\"]:                                                        # since we have segments in result, iterating through each segment\n",
    "     chunks.append({ \"number\" :number, \"title\": title, \"start\": segment[\"start\"],\n",
    "                     \"end\": segment[\"end\"],\"text\" : segment[\"text\"] })                      # appending chunk with metadata to the list\n",
    "\n",
    "  chunksWithMetadata = {\"chunks\" : chunks, \"text\" : result[\"text\"]}                         # creating a dictionary with chunks and full text\n",
    "\n",
    "\n",
    "  with open(f\"audio_jsons/{audio}.json\", \"w\") as f:                                         # writing the chunks with metadata to a JSON file\n",
    "      json.dump(chunksWithMetadata, f)                                                      # dumping the dictionary to the JSON file\n",
    "\n",
    "print(\"Completed\")\n"
   ],
   "id": "3eaee3e3b5fa99df",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/frolt/Git Projects/Data_Science/.venv/lib/python3.13/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 13\u001B[39m\n\u001B[32m     10\u001B[39m number = audio.split(\u001B[33m\"\u001B[39m\u001B[33m_\u001B[39m\u001B[33m\"\u001B[39m)[\u001B[32m1\u001B[39m][:-\u001B[32m4\u001B[39m]                                                         \u001B[38;5;66;03m# extracting number and title from file name\u001B[39;00m\n\u001B[32m     11\u001B[39m title = audio.split(\u001B[33m\"\u001B[39m\u001B[33m_\u001B[39m\u001B[33m\"\u001B[39m)[\u001B[32m0\u001B[39m]                                                               \u001B[38;5;66;03m# extracting title from file name\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m13\u001B[39m result = \u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtranscribe\u001B[49m\u001B[43m(\u001B[49m\u001B[43maudio\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[33;43mf\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43maudios/\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43maudio\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlanguage\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43men\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtask\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtranscribe\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m    \u001B[38;5;66;03m# transcribing audio file\u001B[39;00m\n\u001B[32m     15\u001B[39m chunks = []                                                                               \u001B[38;5;66;03m# creating an empty list to store chunks\u001B[39;00m\n\u001B[32m     16\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m segment \u001B[38;5;129;01min\u001B[39;00m result[\u001B[33m\"\u001B[39m\u001B[33msegments\u001B[39m\u001B[33m\"\u001B[39m]:                                                        \u001B[38;5;66;03m# since we have segments in result, iterating through each segment\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Git Projects/Data_Science/.venv/lib/python3.13/site-packages/whisper/transcribe.py:295\u001B[39m, in \u001B[36mtranscribe\u001B[39m\u001B[34m(model, audio, verbose, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, condition_on_previous_text, initial_prompt, carry_initial_prompt, word_timestamps, prepend_punctuations, append_punctuations, clip_timestamps, hallucination_silence_threshold, **decode_options)\u001B[39m\n\u001B[32m    292\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    293\u001B[39m     decode_options[\u001B[33m\"\u001B[39m\u001B[33mprompt\u001B[39m\u001B[33m\"\u001B[39m] = all_tokens[prompt_reset_since:]\n\u001B[32m--> \u001B[39m\u001B[32m295\u001B[39m result: DecodingResult = \u001B[43mdecode_with_fallback\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmel_segment\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    296\u001B[39m tokens = torch.tensor(result.tokens)\n\u001B[32m    298\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m no_speech_threshold \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    299\u001B[39m     \u001B[38;5;66;03m# no voice activity check\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Git Projects/Data_Science/.venv/lib/python3.13/site-packages/whisper/transcribe.py:201\u001B[39m, in \u001B[36mtranscribe.<locals>.decode_with_fallback\u001B[39m\u001B[34m(segment)\u001B[39m\n\u001B[32m    198\u001B[39m     kwargs.pop(\u001B[33m\"\u001B[39m\u001B[33mbest_of\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[32m    200\u001B[39m options = DecodingOptions(**kwargs, temperature=t)\n\u001B[32m--> \u001B[39m\u001B[32m201\u001B[39m decode_result = \u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43msegment\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    203\u001B[39m needs_fallback = \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m    204\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m    205\u001B[39m     compression_ratio_threshold \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    206\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m decode_result.compression_ratio > compression_ratio_threshold\n\u001B[32m    207\u001B[39m ):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Git Projects/Data_Science/.venv/lib/python3.13/site-packages/torch/utils/_contextlib.py:120\u001B[39m, in \u001B[36mcontext_decorator.<locals>.decorate_context\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    117\u001B[39m \u001B[38;5;129m@functools\u001B[39m.wraps(func)\n\u001B[32m    118\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mdecorate_context\u001B[39m(*args, **kwargs):\n\u001B[32m    119\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[32m--> \u001B[39m\u001B[32m120\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Git Projects/Data_Science/.venv/lib/python3.13/site-packages/whisper/decoding.py:824\u001B[39m, in \u001B[36mdecode\u001B[39m\u001B[34m(model, mel, options, **kwargs)\u001B[39m\n\u001B[32m    821\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m kwargs:\n\u001B[32m    822\u001B[39m     options = replace(options, **kwargs)\n\u001B[32m--> \u001B[39m\u001B[32m824\u001B[39m result = \u001B[43mDecodingTask\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmel\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    826\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m result[\u001B[32m0\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m single \u001B[38;5;28;01melse\u001B[39;00m result\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Git Projects/Data_Science/.venv/lib/python3.13/site-packages/torch/utils/_contextlib.py:120\u001B[39m, in \u001B[36mcontext_decorator.<locals>.decorate_context\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    117\u001B[39m \u001B[38;5;129m@functools\u001B[39m.wraps(func)\n\u001B[32m    118\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mdecorate_context\u001B[39m(*args, **kwargs):\n\u001B[32m    119\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[32m--> \u001B[39m\u001B[32m120\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Git Projects/Data_Science/.venv/lib/python3.13/site-packages/whisper/decoding.py:737\u001B[39m, in \u001B[36mDecodingTask.run\u001B[39m\u001B[34m(self, mel)\u001B[39m\n\u001B[32m    734\u001B[39m tokens = tokens.repeat_interleave(\u001B[38;5;28mself\u001B[39m.n_group, dim=\u001B[32m0\u001B[39m).to(audio_features.device)\n\u001B[32m    736\u001B[39m \u001B[38;5;66;03m# call the main sampling loop\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m737\u001B[39m tokens, sum_logprobs, no_speech_probs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_main_loop\u001B[49m\u001B[43m(\u001B[49m\u001B[43maudio_features\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtokens\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    739\u001B[39m \u001B[38;5;66;03m# reshape the tensors to have (n_audio, n_group) as the first two dimensions\u001B[39;00m\n\u001B[32m    740\u001B[39m audio_features = audio_features[:: \u001B[38;5;28mself\u001B[39m.n_group]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Git Projects/Data_Science/.venv/lib/python3.13/site-packages/whisper/decoding.py:687\u001B[39m, in \u001B[36mDecodingTask._main_loop\u001B[39m\u001B[34m(self, audio_features, tokens)\u001B[39m\n\u001B[32m    685\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    686\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m.sample_len):\n\u001B[32m--> \u001B[39m\u001B[32m687\u001B[39m         logits = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43minference\u001B[49m\u001B[43m.\u001B[49m\u001B[43mlogits\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtokens\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maudio_features\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    689\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m    690\u001B[39m             i == \u001B[32m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m.tokenizer.no_speech \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    691\u001B[39m         ):  \u001B[38;5;66;03m# save no_speech_probs\u001B[39;00m\n\u001B[32m    692\u001B[39m             probs_at_sot = logits[:, \u001B[38;5;28mself\u001B[39m.sot_index].float().softmax(dim=-\u001B[32m1\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Git Projects/Data_Science/.venv/lib/python3.13/site-packages/whisper/decoding.py:163\u001B[39m, in \u001B[36mPyTorchInference.logits\u001B[39m\u001B[34m(self, tokens, audio_features)\u001B[39m\n\u001B[32m    159\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m tokens.shape[-\u001B[32m1\u001B[39m] > \u001B[38;5;28mself\u001B[39m.initial_token_length:\n\u001B[32m    160\u001B[39m     \u001B[38;5;66;03m# only need to use the last token except in the first forward pass\u001B[39;00m\n\u001B[32m    161\u001B[39m     tokens = tokens[:, -\u001B[32m1\u001B[39m:]\n\u001B[32m--> \u001B[39m\u001B[32m163\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdecoder\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtokens\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maudio_features\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkv_cache\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mkv_cache\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Git Projects/Data_Science/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1774\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1775\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Git Projects/Data_Science/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1781\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1782\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1783\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1784\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1785\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1786\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1788\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1789\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Git Projects/Data_Science/.venv/lib/python3.13/site-packages/whisper/model.py:242\u001B[39m, in \u001B[36mTextDecoder.forward\u001B[39m\u001B[34m(self, x, xa, kv_cache)\u001B[39m\n\u001B[32m    239\u001B[39m x = x.to(xa.dtype)\n\u001B[32m    241\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m block \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.blocks:\n\u001B[32m--> \u001B[39m\u001B[32m242\u001B[39m     x = \u001B[43mblock\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mxa\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmask\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkv_cache\u001B[49m\u001B[43m=\u001B[49m\u001B[43mkv_cache\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    244\u001B[39m x = \u001B[38;5;28mself\u001B[39m.ln(x)\n\u001B[32m    245\u001B[39m logits = (\n\u001B[32m    246\u001B[39m     x @ torch.transpose(\u001B[38;5;28mself\u001B[39m.token_embedding.weight.to(x.dtype), \u001B[32m0\u001B[39m, \u001B[32m1\u001B[39m)\n\u001B[32m    247\u001B[39m ).float()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Git Projects/Data_Science/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1774\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1775\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Git Projects/Data_Science/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1781\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1782\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1783\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1784\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1785\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1786\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1788\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1789\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Git Projects/Data_Science/.venv/lib/python3.13/site-packages/whisper/model.py:167\u001B[39m, in \u001B[36mResidualAttentionBlock.forward\u001B[39m\u001B[34m(self, x, xa, mask, kv_cache)\u001B[39m\n\u001B[32m    160\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\n\u001B[32m    161\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    162\u001B[39m     x: Tensor,\n\u001B[32m   (...)\u001B[39m\u001B[32m    165\u001B[39m     kv_cache: Optional[\u001B[38;5;28mdict\u001B[39m] = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m    166\u001B[39m ):\n\u001B[32m--> \u001B[39m\u001B[32m167\u001B[39m     x = x + \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mattn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mattn_ln\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkv_cache\u001B[49m\u001B[43m=\u001B[49m\u001B[43mkv_cache\u001B[49m\u001B[43m)\u001B[49m[\u001B[32m0\u001B[39m]\n\u001B[32m    168\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.cross_attn:\n\u001B[32m    169\u001B[39m         x = x + \u001B[38;5;28mself\u001B[39m.cross_attn(\u001B[38;5;28mself\u001B[39m.cross_attn_ln(x), xa, kv_cache=kv_cache)[\u001B[32m0\u001B[39m]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Git Projects/Data_Science/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1774\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1775\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Git Projects/Data_Science/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1781\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1782\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1783\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1784\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1785\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1786\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1788\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1789\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Git Projects/Data_Science/.venv/lib/python3.13/site-packages/whisper/model.py:99\u001B[39m, in \u001B[36mMultiHeadAttention.forward\u001B[39m\u001B[34m(self, x, xa, mask, kv_cache)\u001B[39m\n\u001B[32m     92\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\n\u001B[32m     93\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m     94\u001B[39m     x: Tensor,\n\u001B[32m   (...)\u001B[39m\u001B[32m     97\u001B[39m     kv_cache: Optional[\u001B[38;5;28mdict\u001B[39m] = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m     98\u001B[39m ):\n\u001B[32m---> \u001B[39m\u001B[32m99\u001B[39m     q = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mquery\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    101\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m kv_cache \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m xa \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m.key \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m kv_cache:\n\u001B[32m    102\u001B[39m         \u001B[38;5;66;03m# hooks, if installed (i.e. kv_cache is not None), will prepend the cached kv tensors;\u001B[39;00m\n\u001B[32m    103\u001B[39m         \u001B[38;5;66;03m# otherwise, perform key/value projections for self- or cross-attention as usual.\u001B[39;00m\n\u001B[32m    104\u001B[39m         k = \u001B[38;5;28mself\u001B[39m.key(x \u001B[38;5;28;01mif\u001B[39;00m xa \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m xa)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Git Projects/Data_Science/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1774\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1775\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Git Projects/Data_Science/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1781\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1782\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1783\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1784\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1785\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1786\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1788\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1789\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Git Projects/Data_Science/.venv/lib/python3.13/site-packages/whisper/model.py:46\u001B[39m, in \u001B[36mLinear.forward\u001B[39m\u001B[34m(self, x)\u001B[39m\n\u001B[32m     45\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x: Tensor) -> Tensor:\n\u001B[32m---> \u001B[39m\u001B[32m46\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[43m.\u001B[49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     47\u001B[39m \u001B[43m        \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     48\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     49\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbias\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbias\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     50\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
